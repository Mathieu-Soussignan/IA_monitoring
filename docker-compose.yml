services:
  fastapi_app:
    build: ./app
    container_name: fastapi-app
    ports:
      - "8000:8000"
    environment:
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - mlops-network
    # Label retiré pour éviter le spam

  uptime-kuma:
    image: louislam/uptime-kuma:latest
    container_name: uptime-kuma
    ports:
      - "3001:3001"
    volumes:
      - ./data/uptime-kuma:/app/data
    restart: unless-stopped
    networks:
      - mlops-network

  prefect:
    image: prefecthq/prefect:3-python3.12
    container_name: prefect-server
    command: prefect server start --host 0.0.0.0
    ports:
      - "4200:4200"
    volumes:
      - ./flows:/opt/prefect/flows
      - ./data/prefect:/root/.prefect
    environment:
      - PREFECT_HOME=/root/.prefect
      - PREFECT_API_DATABASE_CONNECTION_URL=sqlite+aiosqlite:////root/.prefect/prefect.db
      - PREFECT_API_URL=http://prefect-server:4200/api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4200/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    restart: unless-stopped
    networks:
      - mlops-network
    # Label retiré - les notifications Prefect viennent déjà du workflow

  prefect-worker:
    image: prefecthq/prefect:3-python3.12
    container_name: prefect-worker
    command: >
      bash -c "
        sleep 60 &&
        prefect config set PREFECT_API_URL=http://prefect-server:4200/api &&
        prefect work-pool create --type process default-pool --overwrite &&
        prefect worker start --pool default-pool --name ml-worker-docker
      "
    environment:
      - PREFECT_API_URL=http://prefect-server:4200/api
    volumes:
      - ./flows:/opt/prefect/flows
    depends_on:
      prefect:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - mlops-network
    # Label retiré pour éviter la duplication avec le workflow

  ml-api:
    build: ./ml_api
    container_name: ml-api
    ports:
      - "8001:8001"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5555
    volumes:
      - ./ml_api/models:/app/models
      - ./data/ml-api:/app/data
    depends_on:
      mlflow:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - mlops-network
    labels:
      - "discord-logger.enabled=true"  # Garde uniquement pour les erreurs critiques ML

  mlflow:
    image: python:3.11-slim
    container_name: mlflow-server
    ports:
      - "5555:5555"
    working_dir: /mlflow
    command: >
      bash -c "
        apt-get update && 
        apt-get install -y build-essential procps curl &&
        pip install --upgrade pip setuptools wheel &&
        pip install mlflow[extras]==2.8.1 &&
        mlflow server --host 0.0.0.0 --port 5555 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns
      "
    volumes:
      - ./data/mlflow:/mlflow
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - mlops-network
    # Label retiré - MLflow est verbeux

  docker-discord-logger:
    image: ghcr.io/1randomdev/docker-discord-logger:latest
    container_name: docker-discord-logger
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
      - LOG_LEVEL=ERROR  # Seulement les erreurs
      - FILTER_INCLUDE_LABEL=discord-logger.enabled=true
      - FILTER_EXCLUDE_PATTERN=health|ping|GET|POST  # Exclure le bruit
      - RATE_LIMIT=true  # Limiter la fréquence
    restart: unless-stopped
    networks:
      - mlops-network

networks:
  mlops-network:
    driver: bridge
    name: mlops-network